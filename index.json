[{"authors":["admin"],"categories":null,"content":"I enjoy working within the field of data engineering and web analytics. This site is build in order for me to document some of my work, so others can benefit from it, as well as serving as a memory bank for storing solutions i\u0026rsquo;ve build through time.\n","date":1559952000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1559952000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I enjoy working within the field of data engineering and web analytics. This site is build in order for me to document some of my work, so others can benefit from it, as well as serving as a memory bank for storing solutions i\u0026rsquo;ve build through time.","tags":null,"title":"Danny Mawani Holmgaard","type":"authors"},{"authors":null,"categories":null,"content":"Introduction This post is based on a project where we needed to see how many transactions we were actually missing in Google Analytics.\nThe how to This process is quite simple, we will be pulling out transaction id\u0026rsquo;s and then make it into a list. After that we compare that list with another\nga_id \u0026lt;- \u0026quot;yourgaid\u0026quot; data \u0026lt;- google_analytics(ga_id, date_range = c(\u0026quot;2019-01-23\u0026quot;, \u0026quot;2019-02-13\u0026quot;), metrics = \u0026quot;users\u0026quot;, dimensions = c(\u0026quot;transactionId\u0026quot;), max = -1) #Your transaction ids rowa \u0026lt;- as.list(data$transactionId) #the other list of transaction ids rowb \u0026lt;- as.list(sfData$ti) #make them into characters rowa \u0026lt;- as.character(rowa) rowb \u0026lt;- as.character(rowb) #Only get the ones that doesn't match list1 \u0026lt;- setdiff(rowb, rowa) #Make a dataframe from only those who are missing df \u0026lt;- sfData[sfData$ti %in% list1, ]  Conclusion This is a very short tutorial, it is not formatted very pretty, but it should get the trick done in terms of validating if anything should be missing in terms of transactions in Google Analytics. Please leave a comment should you need further elaboration on this progress!\n","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"a5d40625465eddc47f83877e388db8aa","permalink":"/post/measurement-protocol-usecases/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/measurement-protocol-usecases/","section":"post","summary":"How to compare data from GA to another dataset to see if there are any discrepencies","tags":null,"title":"Detect missing data in GA with R","type":"post"},{"authors":["Danny Mawani Holmgaard"],"categories":null,"content":"the slides\n ","date":1559952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559952000,"objectID":"d291d65b623708fee9f6a76e3b97b675","permalink":"/talk/superweek-2019/","publishdate":"2019-06-08T00:00:00Z","relpermalink":"/talk/superweek-2019/","section":"talk","summary":"Introduction on scheduling tasks of Google Cloud","tags":["R","GCP","Google Cloud"],"title":"R on the Google Cloud Platform - Scheduling tasks","type":"talk"},{"authors":null,"categories":null,"content":"Table of Contents  Introduction How the measurement protcol works Usecases  Uploading refunds Uploading transactions   words of caution  1. Create filters to block views 2. Remove the \u0026ldquo;Exclude all hits from known bots and spiders\u0026rdquo; checkmark 3. Latency   conlusion   Introduction This blogpost was inspired by a release to a website which had some last minute changed that when the site when live, caused a javaScript error that blocked the ecommerce transaction data to not populate.\nWith this error, the client lost 1800+ transactions to the site meaning that we had to upload these in the right currency format to make sure that all the data was still avaliable.\nHow the measurement protcol works Whenever you visit a website, Google Analytic will collect information by sending a long list of query parameters to an endpoint, to which it is stored and modelled to show information in GA. Visiting this blogpost will for an example generate a network call similar to this:\nhttps://www.google-analytics.com/r/collect?v=1\u0026amp;_v=j73\u0026amp;a=1679354847\u0026amp;t=pageview\u0026amp;_s=1\u0026amp;dl=https%3A%2F%2Fwww.mawani.dk%2Fpost%2Fmeasurement-protocol-usecases%2F\u0026amp;ul=en-us\u0026amp;de=UTF-8\u0026amp;dt=Creating%20a%20workflow%20with%20measurement%20protocol%20and%20R%20%7C%20DMH%20Analytics\u0026amp;sd=24-bit\u0026amp;sr=1440x900\u0026amp;vp=1440x256\u0026amp;je=0\u0026amp;_u=QACAAAAB~\u0026amp;jid=651243071\u0026amp;gjid=1319476248\u0026amp;cid=1164110852.1529450664\u0026amp;tid=UA-134673438-1\u0026amp;_gid=106302445.1550868348\u0026amp;_r=1\u0026amp;gtm=2wg241WBTJ7HR\u0026amp;z=1265093896  This will tell Google Analytics that:\n The URL is this one My browser language is en-us what my device id is from the cookie so it can recognize me as a new or returning user What tracking ID it should populate the data to What my session ID is.  What measurement protocol will do is to emulate the same types of parameters and have it populate the data in GA.\nFor a more detailed view on measurement protocol I would advise you to visit Optimize Smart for their deepgoing description.\nUsecases I have used measurement protocol for a various number of things. As you can send in all the supported information, this is a great area to explore in terms of improving your data collection. As for many of my other posts, I will be using another package created by Mark Edmonson called googleMeasureR to send the hits to Google Analytics, however you can easily transfer the way of doing this to any language of your choice such as Python, javaScript, PHP etc.\nUploading refunds To upload refunds you first need a list of all the transactions that are missing. If you are on a site with multiple currencies it is also quite important that you can specify what unit that you are adding data to, so you are sure that it is populated correctly.\nFirst thing that need to be done is to make sure that the data is loaded into R. I have chosen to rename the columns to the GA naming convention for measurement protocol, but it is not important:\n   Once that is made, we need to either have the client id (Google Analytics Cookie ID for identifying people), or create one yourself. This can be done by this code:\n#loading the library library(stringi) #the count of rows you need to upload n \u0026lt;- nrow(yourDataframe) #create the ids paste(\u0026quot;1.2.\u0026quot;,stri_rand_strings(n, 10, pattern = \u0026quot;[0-9]\u0026quot;),\u0026quot;.\u0026quot;,stri_rand_strings(n, 10, pattern = \u0026quot;[0-9]\u0026quot;), sep = \u0026quot;\u0026quot;) #output will look something like this if you print it out in the console [1] \u0026quot;1.2.6237558844.6715115260\u0026quot; \u0026quot;1.2.4893337628.0287915875\u0026quot; \u0026quot;1.2.1414860945.6106576917\u0026quot; [4] \u0026quot;1.2.8992586956.6450277842\u0026quot; \u0026quot;1.2.2032023475.7135641438\u0026quot; \u0026quot;1.2.1490282359.1139988407\u0026quot; [7] \u0026quot;1.2.7613957961.8692578524\u0026quot; \u0026quot;1.2.8481705025.8828767075\u0026quot; \u0026quot;1.2.1331455569.2063291053\u0026quot; [10] \u0026quot;1.2.9292335596.4531869013\u0026quot; ### add it to the dataframe yourDataframe$cid \u0026lt;- paste(\u0026quot;1.2.\u0026quot;,stri_rand_strings(n, 10, pattern = \u0026quot;[0-9]\u0026quot;),\u0026quot;.\u0026quot;,stri_rand_strings(n, 10, pattern = \u0026quot;[0-9]\u0026quot;), sep = \u0026quot;\u0026quot;)  Now that a client id is added we are ready to push the refunds into Google Analytics:\n####upload v \u0026lt;- 1 #version cs \u0026lt;- \u0026quot;measurementprotocol\u0026quot; #source cm \u0026lt;- \u0026quot;refund\u0026quot; #medium t \u0026lt;- \u0026quot;event\u0026quot; #type ec \u0026lt;- \u0026quot;Ecommerce\u0026quot; #event category ea \u0026lt;- \u0026quot;measurementProtocol\u0026quot; #event action el \u0026lt;- \u0026quot;refund\u0026quot; #event label tid \u0026lt;- \u0026quot;UA-1234567-1\u0026quot; #Google Analytics ID pa \u0026lt;- \u0026quot;refund\u0026quot; #product action ta \u0026lt;- \u0026quot;measurementprotocol\u0026quot; #transaction affiliation #for each row in the dataframe send a hit with measurement protocol for(i in 1:nrow(yourDataframe)) { cid \u0026lt;- yourDataframe$cid[i] ti \u0026lt;- yourDataframe$ti[i] tr \u0026lt;- yourDataframe$tr[i] cu \u0026lt;- yourDataframe$cu[i] gmr_post(list(v=v,cs=cs,cm=cm,t=t,ec=ec,ea=ea,el=el,tid=tid,cid=cid,pa=pa,ti=ti,tr=tr,cu=cu,ta=ta,ni=\u0026quot;1\u0026quot;))  And there you have it, the refunds should be uploaded.\nUploading transactions This is actually the exact same steps you go through - the primary difference is that you need to change the product action from refund to purchase:\n####upload v \u0026lt;- 1 #version cs \u0026lt;- \u0026quot;measurementprotocol\u0026quot; #source cm \u0026lt;- \u0026quot;purchase\u0026quot; #medium t \u0026lt;- \u0026quot;event\u0026quot; #type ec \u0026lt;- \u0026quot;Ecommerce\u0026quot; #event category ea \u0026lt;- \u0026quot;measurementProtocol\u0026quot; #event action el \u0026lt;- \u0026quot;refund\u0026quot; #event label tid \u0026lt;- \u0026quot;UA-1234567-1\u0026quot; #Google Analytics ID pa \u0026lt;- \u0026quot;purchase\u0026quot; #product action ta \u0026lt;- \u0026quot;measurementprotocol\u0026quot; #transaction affiliation #for each row in the dataframe send a hit with measurement protocol for(i in 1:nrow(yourDataframe)) { cid \u0026lt;- yourDataframe$cid[i] ti \u0026lt;- yourDataframe$ti[i] tr \u0026lt;- yourDataframe$tr[i] cu \u0026lt;- yourDataframe$cu[i] gmr_post(list(v=v,cs=cs,cm=cm,t=t,ec=ec,ea=ea,el=el,tid=tid,cid=cid,pa=pa,ti=ti,tr=tr,cu=cu,ta=ta,ni=\u0026quot;1\u0026quot;))  words of caution When you add data to Google Analytics, it is not possible to remove it again, so remember to test what you are doing beforehand and be sure that what you are doing is correct.\nBelow is some areas that you need to remember when doing uploads through measurement protocol:\n1. Create filters to block views Create an exclude filter to exclude all event action called \u0026ldquo;measurementprotocol\u0026rdquo;. This ensures that you data is only send to the views you need.\n2. Remove the \u0026ldquo;Exclude all hits from known bots and spiders\u0026rdquo; checkmark In some instances I saw that the measurement protocol hits where blocked when this was not checked off. Remember to switch it on the day after so you are secured against people spamming your analytics account with bot traffic.\n3. Latency There is a latency from the the data is send to that it is populated. Unfortunately if you add / remove filters before the day is over it will take in / remove the hits from measurement protocol meaning that you will endanger your datacollection.\nconlusion This is a simple how-to guide on doing basic things with measurement protocol, there are a lot about datacleaning that could have been included but it would be out of the scope of this blogpost.\nIn terms of all the parameters added in the call, there are many that could have been excluded, however i choose to add them as it will be easier to filter them out in different instances should you need to do that.\nA main issue with measurement protocol, when you don\u0026rsquo;t have the right client id is that you do loose the user behaviour and affect your traffic if you are doing bulk uploads in a day. It is therefore important to consider if this is the right solution for the task, and be sure that the data being send in is correct.\n","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551398400,"objectID":"b15f1e67baa8810ae3f14e88ef28dc55","permalink":"/post/detect-missing-data-with-r-a-google-analytics-example/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/post/detect-missing-data-with-r-a-google-analytics-example/","section":"post","summary":"This is a simple how-to guide on doing basic things with measurement protocol","tags":null,"title":"Creating a workflow with measurement protocol and R","type":"post"},{"authors":null,"categories":null,"content":"Table of Contents  Background Usecase The code  1. Connect To Google Analytics 2. Setting up the script to pull from multiple properties   Conclusion   Background Being in an agency, we often have to do benchmarks, reports etc. that require us to pull data from multiple Google Analytics properties.\nUsecase One of our client have multiple properties each containing 3 business units, a B2B, B2C and B2G (Business to government). To make sure that we could reproduce the reporting for them, we build an R script that:\n Pulls Google Analytics data Adds business unit and country to the dataframe as additional variables / columns Merges the data into another dataframe  The code To extract the data, use the googleAnalyticsRand googleAuthRpackage made by Mark Edmonson. To see more information about installing the packages and using the libraries please check out the site made explaining how the package work here\n1. Connect To Google Analytics To begin with we must first authenticate to Google Analytics.\nlibrary(googleAnalyticsR) googleAnalyticsR::ga_auth()  Next you will be asked to log in with your Google Account. Once that is done, we are ready to do the rest of the script.\n Remember to authenticate with the account you want access to   2. Setting up the script to pull from multiple properties To combine different properties we are fest specifying the views we need and adding them to a list. Once that is done we will create 2 corresponding lists with business units and countries.\n#this are the view links which can be find under view settings or through the URL of the view - If you are used to working with this package, you can also do an extraction of all your views directly from R. The below views are fake. #Danish dk_b2b \u0026lt;- \u0026quot;123213213\u0026quot; dk_b2c \u0026lt;- \u0026quot;543454533\u0026quot; dk_b2g \u0026lt;- \u0026quot;173714215\u0026quot; #Finnish fi_b2b \u0026lt;- \u0026quot;345345435\u0026quot; fi_b2c \u0026lt;- \u0026quot;345435345\u0026quot; fi_b2g \u0026lt;- \u0026quot;234234232\u0026quot; #French fr_b2b \u0026lt;- \u0026quot;655464555\u0026quot; fr_b2c \u0026lt;- \u0026quot;989834589\u0026quot; fr_b2g \u0026lt;- \u0026quot;039485309\u0026quot; #adding all the views to a list views \u0026lt;- c(dk_b2b,dk_b2c,dk_b2g,fi_b2b,fi_b2c,fi_b2g,fr_b2b,fr_b2c,fr_b2g) #countries should be in the same order as your list above, we will use this to add attributes to the dataframe countries \u0026lt;- c(\u0026quot;DK\u0026quot;,\u0026quot;DK\u0026quot;,\u0026quot;DK\u0026quot;,\u0026quot;FI\u0026quot;,\u0026quot;FI\u0026quot;,\u0026quot;FI\u0026quot;,\u0026quot;FR\u0026quot;,\u0026quot;FR\u0026quot;,\u0026quot;FR\u0026quot;) #same approach for business units BU \u0026lt;- c(\u0026quot;B2B\u0026quot;,\u0026quot;B2C\u0026quot;,\u0026quot;B2G\u0026quot;,\u0026quot;B2B\u0026quot;,\u0026quot;B2C\u0026quot;,\u0026quot;B2G\u0026quot;,\u0026quot;B2B\u0026quot;,\u0026quot;B2C\u0026quot;,\u0026quot;B2G\u0026quot;) #Set a start and enddate startDate \u0026lt;- \u0026quot;2018-01-01\u0026quot; endDate \u0026lt;- as.character(Sys.Date()-1) #Set dimensions and metrics dimensions \u0026lt;- c(\u0026quot;year\u0026quot;,\u0026quot;sourceMedium\u0026quot;,\u0026quot;campaign\u0026quot;) metrics \u0026lt;- c(\u0026quot;sessions\u0026quot;,\u0026quot;transactions\u0026quot;,\u0026quot;transactionRevenue\u0026quot;) #create an empty dataframe upload \u0026lt;- data.frame() #pulling the data for(i in seq_along(views)) { data \u0026lt;- google_analytics(views[i], date_range = c(startDate,endDate), metrics = metrics, dimensions = dimensions,max = -1) data$country \u0026lt;- countries[i] data$bu \u0026lt;- BU[i] upload \u0026lt;- rbind(upload,data) }  The end states that for each element in the view list, then run the analytics script, apply the data and business unit to the corresponding list item to the dataframe \u0026ldquo;data\u0026rdquo;, and then add it to the empty dataframe.\n Since writing this post i now recommend using mapply (or future_mapply to run it faster in parallel). I will however not change this, as the for loop might do a better job explaining what happens and how the process work.   Conclusion Now that the dataframe has been made it is up to you what to do with it. you can either upload it to bigQuery, do some statistics with R and some plot with ggplot2 or just write it down to a CSV file with r write.csv2(upload,\u0026quot;yourFileName.csv\u0026quot;) and work with it in another tool like Excel, Tableau or powerBI.\n","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551398400,"objectID":"c02261a7368aa46db859ff59f6df9086","permalink":"/post/pull-data-from-multiple-ga-properties/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/post/pull-data-from-multiple-ga-properties/","section":"post","summary":"Benchmarking your data can be rough. In this post we go through how to pull data from multiple GA accounts","tags":null,"title":"Pull data from multiple Google Analytics Properties with R","type":"post"},{"authors":null,"categories":null,"content":"Table of Contents  Background Why is sourcing from github smart? The how-to part  1. Setting up a github account 2. Creating a bucket in Google Cloud Storage 3. Creating a trigger with Cloud Build 4. Setting up the YALM 5. Sourcing scripts from Cloud Storage   Thoughts and conclusion   source-r-with-github\nBackground In my company, we have gone from 1 person working with adhoc assignment with R, to 4 persons within the last year. This set\u0026rsquo;s up a whole new level of requirements to ensure quality, stability and safety when it comes to working with datamodels and API calls. Furthermore, there is also an aspect of reusability that needed to be set up to ensure that we could produce our solutions faster,and better updated.\nTo do this, we started looking into differen\u0026rsquo;t types of systems to work with our code. In the end we have selected Github as our main source of creating our code and documentation.\nTo get to know how to do this, I actually used this guide: Automated Static Website Publishing with Cloud Build , and used most of the principles in the guide to set up our setup.\nWhy is sourcing from github smart? Github allows us to:\n Share code easily Scale projects to other customers Ensure documentation Making updates to code safe and with the possibility to roll-back should something break See who have created code Source Scripts directly in R  Unfortunately, going into how to use Github is a bit out of the scope for this post, however I recommend going to Github and read their documentation and do a few searches on the net to get started.\nThe how-to part In order to source R scripts from github there are a few things you need to have ready in order to get ready:\n1. Setting up a github account One of the first thing you will need is to actually create a Github account . This can be done on the frontpage:\n   Once that is done, create a repository:\n   Recently, it\u0026rsquo;s been possible to create private repositories for free1. As we are multiple users that are using Github right now, we did manage to get our financaial department to approve the monthly 7$ account fee, however in theory, you could create a shared login to help get you started.\n2. Creating a bucket in Google Cloud Storage   Set up billing for GCP (Google Cloud Platform)  Create a bucket in Google Cloud Storage):      3. Creating a trigger with Cloud Build Now, this part is something that is already documented in the GCP documentaion. To avoid copying the same guide in this post, instead go to this page and follow the steps from the headling: Set up automated builds until you see this line: \u0026ldquo;Now, create a cloudbuild.yaml\u0026rdquo;. From there, you will not need to follow the rest of the steps to continue this guide.\n4. Setting up the YALM YALM stands for \u0026ldquo;Yet Another Markup Language\u0026rdquo; and will be added to Github. From here, the YALM file sends the information to Cloud Build that copies the updates on Github into the Cloud Storage Bucket just created.\nIn your Github repo, click on \u0026ldquo;Create new file\u0026rdquo;. Now, add the following YALM syntax in the edit section:\nsteps: - name: gcr.io/cloud-builders/gsutil args: [\u0026quot;-m\u0026quot;, \u0026quot;rsync\u0026quot;, \u0026quot;-r\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;-d\u0026quot;, \u0026quot;.\u0026quot;, \u0026quot;gs://yourfolderincloudstorage/ifneededthencreateasubfolder\u0026quot;]  save the file as cloudbuild.yaml.\nOnce that is done, each change made to your repository will be pushed directly to Google Cloud Storage, where it is possible to run R scripts.\n5. Sourcing scripts from Cloud Storage Playing around with R and the Google API universe usually means using something that Mark Edmonson has build, and this post is not an exception.\nWe will be using the Package called \u0026ldquo;googleCloudStorageR\u0026rdquo;, which you can find more information about here.\nTo source a script from Google Cloud Storage, use this R codeto authenticate and source the script you need:\n#install.package(\u0026quot;googleCloudStorageR\u0026quot;) if you have not installed it yet #load the library library(googleCloudStorageR) #Authenticate gcs_auth() googleCloudStorageR::gcs_source('yoursubfolderifyouhaveone/yourscript.R', bucket = 'yourcreatedbucket')  And voila. This means that you can always download your R files where ever you need it, build on it, add the information back to github and source the script from a third place without having to have multiple copies of your code laying around.\nThoughts and conclusion This post have showed how to use Github to run R scripts and keep them updated. I do recommend trying to document and automate as much as possible when working with R, however this should only be used whenever it makes sense. If you are building something on the fly that will only be used for a specific tasks once, then it might not make sense to go through all of this to make your workflow optimal.\n  A repository is a folder to which your content in github is stored. This is usually your code files. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551398400,"objectID":"20f5c3afb48781d38a3bae657fadd4f8","permalink":"/post/source-r-with-github/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/post/source-r-with-github/","section":"post","summary":"Making changes to your pipelines can be rough if you are multiple people working on the same project. This guide shows you how to use Github to make it easier","tags":null,"title":"Source R scripts from github through Google Cloud Storage","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Danny Mawani Holmgaard"],"categories":null,"content":"the slides\n  Superweek2019 dmo presentation  from Danny Mawani Olsen ","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"bb29481c1ff6dfeb0834bdbec6aa1570","permalink":"/talk/r-on-google-cloud-platform/","publishdate":"2019-02-01T00:00:00Z","relpermalink":"/talk/r-on-google-cloud-platform/","section":"talk","summary":"Automation within data engineering and processes in the business","tags":["automation"],"title":"Superweek 2019 - A tale of automation in data engineering","type":"talk"},{"authors":["Danny Mawani Holmgaard"],"categories":null,"content":"Se videoen her:   ","date":1543658400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543658400,"objectID":"9581327b5aad1565039318a3a054407b","permalink":"/talk/blackfriday/","publishdate":"2018-12-03T00:00:00Z","relpermalink":"/talk/blackfriday/","section":"talk","summary":"Dansk talk omkring de emner der er nødvendigt at have styr på inden man skal opsætte sin tracking før under og efter black friday","tags":["analytics","gtm","loadspeed"],"title":"Black friday seminar","type":"talk"},{"authors":["Danny Mawani Holmgaard"],"categories":null,"content":"  GDPR within Google Tag Manager - Measurecamp 2018  from Danny Mawani Olsen ","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543622400,"objectID":"be41ac579a5ed9af211e425afad545b4","permalink":"/talk/ip-anonymization-while-excluding-internal-trafic/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/talk/ip-anonymization-while-excluding-internal-trafic/","section":"talk","summary":"How to keep GDPR compliant with Google Tag Manager","tags":["GTM","GDPR"],"title":"GDPR with Google Tag Manager","type":"talk"},{"authors":["Danny Mawani Holmgaard"],"categories":null,"content":" Original Link\n  Anonymization of IP adresses with Google Tag Manager  from Danny Mawani Olsen ","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543622400,"objectID":"162b332d1208a336a4a1810bd33954e3","permalink":"/talk/gdpr-with-google-tag-manager/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/talk/gdpr-with-google-tag-manager/","section":"talk","summary":"Anonymizing ip adresses while excluding internal traffic on your site.","tags":["GTM","GDPR"],"title":"How to anonymize IP adresses and still be able to exclude internal traffic","type":"talk"},{"authors":["Danny Mawani Holmgaard"],"categories":null,"content":"the slides\n  Rclass  from Danny Mawani Olsen   full link here\n","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543622400,"objectID":"40221d0fc05a29ade5faf4d3e91facc9","permalink":"/talk/r-introduction-class-measurecamp/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/talk/r-introduction-class-measurecamp/","section":"talk","summary":"Introduction class for R","tags":["R","Education"],"title":"R introduction class for measurecamp","type":"talk"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"}]